import os
from langchain.text_splitter import RecursiveCharacterTextSplitter
from CLLeMensLangchain.schema.loaders import Loaders
from typing import Union, List
from langchain.document_loaders import TextLoader
from langchain.docstore.document import Document
import speech_recognition as sr
from deepmultilingualpunctuation import PunctuationModel
import io
from pydub import AudioSegment
from pydub.silence import split_on_silence


class AudioLoader(Loaders):
    def __init__(self, file_path: str):
        """
        Initialize DocxLoader

        :param file_path: The path to the file to be loaded
        """
        self.file_path = file_path
        if "~" in self.file_path:
            self.file_path = os.path.expanduser(self.file_path)

        # Initialize the punctuation model and speech recognition object
        self.model = PunctuationModel()
        self.recognizer = sr.Recognizer()

    def transcribe_audio_chunk(self, audio_chunk):
        # Convert pydub.AudioSegment to a byte-like object
        buffer = io.BytesIO()
        audio_chunk.export(buffer, format="wav")
        buffer.seek(0)

        with sr.AudioFile(buffer) as source:
            audio_listened = self.recognizer.record(source)
            try:
                text = self.recognizer.recognize_google(audio_listened)
                return text
            except sr.UnknownValueError:
                return "[Unrecognized segment]"
            except sr.RequestError:
                return "[API Unavailable]"

    def add_punctuation(self, text: str) -> str:
        result = self.model.restore_punctuation(text)
        sentences = result.split('. ')
        sentences = [s.capitalize() for s in sentences]
        return '. '.join(sentences)

    def load(self) -> Union[str, List[str], List[Document]]:
        """
        Load content from an audio file and return its transcription
        :return: The transcribed content of the audio
        """
        try:
            sound = AudioSegment.from_file(self.file_path)
            chunks = split_on_silence(sound,
                                      min_silence_len=700,
                                      silence_thresh=sound.dBFS - 14,
                                      keep_silence=500,
                                      )

            whole_text = ""
            for audio_chunk in chunks:
                text = self.transcribe_audio_chunk(audio_chunk)
                whole_text += text + " "

            formatted_text = self.add_punctuation(whole_text)

            cache_path = self.file_path.replace("uploads", "cache")

            # Append the new extension .txt
            cache_file_path = cache_path + ".txt"

            print("CACHE PATH:", cache_file_path)
            # Den String in die Datei schreiben
            with open(cache_file_path, 'w') as file:
                file.write(formatted_text)

            try:
                content = TextLoader(self.file_path)
                pages = content.load()
            except Exception as e:
                return f"Error loading audio: {str(e)}"

            return pages

        except Exception as e:
            return f"Error loading audio: {str(e)}"

    def chunkDocument(self, document: List[Document], chunkSize=750) -> List[Document]:
        """Chunk a document into smaller parts for processing via embeddings
        :param document: The document to be chunked (generated by load())
        :param chunkSize: The size of the chunks (default 750), greatly affects the result of the embeddings & prompts
        :return: The chunked document as a list of Langchain Documents with metadata [page, source, start_index]
        """
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunkSize,
            chunk_overlap=20,
            add_start_index=True,
        )
        chunked_content = text_splitter.split_documents(document)
        return chunked_content
